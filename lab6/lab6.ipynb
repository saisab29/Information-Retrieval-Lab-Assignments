{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0560988",
   "metadata": {},
   "source": [
    "# Lab 6: Text Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f16a4",
   "metadata": {},
   "source": [
    "## K-Means Text Clustering on Movie Reviews\n",
    "Objective\n",
    "\n",
    "Cluster a set of movie reviews into groups based on their content similarity using K-Means clustering and TF-IDF vectorization.\n",
    "\n",
    "1. Movie Reviews Dataset\n",
    "\n",
    "We create a small sample dataset of movie reviews:\n",
    "\n",
    "docs = [\n",
    "    \"I loved the movie, the acting was fantastic\",\n",
    "    \"The film was boring and too long\",\n",
    "    \"Amazing plot and great visuals\",\n",
    "    \"Waste of time, not recommended\",\n",
    "    \"Average movie, some good scenes but dull overall\",\n",
    "]\n",
    "\n",
    "2. TF-IDF Vectorization\n",
    "\n",
    "Convert the text reviews into numerical vectors using TfidfVectorizer.\n",
    "This captures the importance of each word relative to the document and the corpus.\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "3. K-Means Clustering\n",
    "\n",
    "Use the K-Means algorithm to cluster the reviews into k groups.\n",
    "Each cluster should ideally group reviews with similar sentiment or content.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=2, random_state=42)\n",
    "model.fit(X)\n",
    "clusters = model.labels_\n",
    "\n",
    "4. Assign Cluster Labels\n",
    "\n",
    "Each review is assigned a cluster label:\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Doc {i} -> Cluster {clusters[i]}: {doc}\")\n",
    "\n",
    "\n",
    "Example output:\n",
    "\n",
    "Doc 0 -> Cluster 0: I loved the movie, the acting was fantastic\n",
    "Doc 1 -> Cluster 1: The film was boring and too long\n",
    "Doc 2 -> Cluster 0: Amazing plot and great visuals\n",
    "Doc 3 -> Cluster 1: Waste of time, not recommended\n",
    "Doc 4 -> Cluster 1: Average movie, some good scenes but dull overall\n",
    "\n",
    "5. Notes\n",
    "\n",
    "TF-IDF represents text numerically to capture word importance.\n",
    "\n",
    "K-Means groups similar reviews together.\n",
    "\n",
    "In this example, cluster 0 corresponds mostly to positive reviews, while cluster 1 corresponds mostly to negative or neutral reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a884e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0 -> Cluster 0: I loved the movie, the acting was fantastic\n",
      "Doc 1 -> Cluster 0: The film was boring and too long\n",
      "Doc 2 -> Cluster 0: Amazing plot and great visuals\n",
      "Doc 3 -> Cluster 0: Waste of time, not recommended\n",
      "Doc 4 -> Cluster 1: Average movie, some good scenes but dull overall\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_text_clustering(docs, k=2):\n",
    "    \"\"\"\n",
    "    Cluster text documents using K-Means.\n",
    "    \"\"\"\n",
    "    # Convert documents to TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "\n",
    "    # Fit K-Means\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "\n",
    "    # Assign cluster labels\n",
    "    clusters = model.labels_\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Doc {i} -> Cluster {clusters[i]}: {doc}\")\n",
    "\n",
    "# -------------------------\n",
    "# Movie Reviews Dataset\n",
    "# -------------------------\n",
    "docs = [\n",
    "    \"I loved the movie, the acting was fantastic\",\n",
    "    \"The film was boring and too long\",\n",
    "    \"Amazing plot and great visuals\",\n",
    "    \"Waste of time, not recommended\",\n",
    "    \"Average movie, some good scenes but dull overall\",\n",
    "]\n",
    "\n",
    "# Cluster into 2 groups: Positive vs Negative reviews\n",
    "kmeans_text_clustering(docs, k=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d60c42",
   "metadata": {},
   "source": [
    "## K-Medoids Text Clustering on Movie Reviews\n",
    "Objective\n",
    "\n",
    "Cluster a set of movie reviews into groups based on their content similarity using K-Medoids clustering and TF-IDF vectorization.\n",
    "\n",
    "K-Medoids is similar to K-Means but selects actual data points as cluster centers (medoids), making it more robust to outliers.\n",
    "\n",
    "1. Movie Reviews Dataset\n",
    "\n",
    "We use the same sample movie reviews as in the K-Means lab:\n",
    "\n",
    "docs = [\n",
    "    \"I loved the movie, the acting was fantastic\",\n",
    "    \"The film was boring and too long\",\n",
    "    \"Amazing plot and great visuals\",\n",
    "    \"Waste of time, not recommended\",\n",
    "    \"Average movie, some good scenes but dull overall\",\n",
    "]\n",
    "\n",
    "2. TF-IDF Vectorization\n",
    "\n",
    "Convert the text reviews into numerical vectors:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "doc_vectors = vectorizer.fit_transform(docs).toarray()\n",
    "\n",
    "\n",
    "Each review is represented as a vector of word importance.\n",
    "\n",
    "Stopwords are removed to focus on meaningful content.\n",
    "\n",
    "3. Compute Distance Matrix\n",
    "\n",
    "Compute pairwise Euclidean distances between document vectors:\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "dist_matrix = euclidean_distances(doc_vectors)\n",
    "\n",
    "4. K-Medoids Clustering\n",
    "\n",
    "Perform K-Medoids clustering:\n",
    "\n",
    "import kmedoids\n",
    "\n",
    "km = kmedoids.KMedoids(n_clusters=2, method='fasterpam', random_state=42)\n",
    "kmedoids_result = km.fit(dist_matrix)\n",
    "\n",
    "\n",
    "n_clusters=2 specifies the number of clusters.\n",
    "\n",
    "method='fasterpam' is an efficient algorithm for medoid selection.\n",
    "\n",
    "5. Cluster Results\n",
    "\n",
    "Retrieve medoids and cluster assignments:\n",
    "\n",
    "print(\"KMedoids Medoid Indices:\", kmedoids_result.n_clusters)\n",
    "print(\"KMedoids Cluster Labels:\", kmedoids_result.labels_)\n",
    "\n",
    "\n",
    "medoids are the representative documents for each cluster.\n",
    "\n",
    "labels_ assign each review to a cluster.\n",
    "\n",
    "6. Notes\n",
    "\n",
    "K-Medoids is less sensitive to outliers than K-Means.\n",
    "\n",
    "Works well when using a precomputed distance matrix, like TF-IDF with Euclidean distance.\n",
    "\n",
    "Cluster assignments can reveal positive vs negative reviews or similar thematic content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567f96e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMedoids Medoid Indices: 2\n",
      "KMedoids Cluster Labels: [1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import kmedoids\n",
    "\n",
    "# --- TF-IDF Vectorization ---\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "doc_vectors = vectorizer.fit_transform(docs).toarray()\n",
    "\n",
    "# --- KMedoids Clustering ---\n",
    "dist_matrix = euclidean_distances(doc_vectors)\n",
    "km = kmedoids.KMedoids(n_clusters=2, method='fasterpam', random_state=42)\n",
    "kmedoids_result = km.fit(dist_matrix)\n",
    "print(\"KMedoids Medoid Indices:\", kmedoids_result.n_clusters)\n",
    "print(\"KMedoids Cluster Labels:\", kmedoids_result.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f589c",
   "metadata": {},
   "source": [
    "## Text Shingling\n",
    "Objective\n",
    "\n",
    "To measure the similarity between movie reviews based on shared k-shingles (substrings of length k). This is useful for detecting near-duplicate reviews or clustering similar text documents.\n",
    "\n",
    "1. Shingles Generation\n",
    "\n",
    "A shingle is a substring of length k extracted from a document. By converting a document into a set of shingles, we can compare the overlap between documents.\n",
    "\n",
    "def get_shingles(text, k=3):\n",
    "    \"\"\"Generate k-shingles (substrings of length k).\"\"\"\n",
    "    text = text.lower()  # normalize to lowercase\n",
    "    return set([text[i:i+k] for i in range(len(text) - k + 1)])\n",
    "\n",
    "\n",
    "Example:\n",
    "\"movie\" with k=3 → {'mov', 'ovi', 'vie'}\n",
    "\n",
    "2. Jaccard Similarity\n",
    "\n",
    "The Jaccard Similarity between two documents is defined as:\n",
    "\n",
    "\n",
    "J(A,B)=\n",
    "∣A∪B∣ /\n",
    "∣A∩B∣\n",
    "\t​\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "\n",
    "A and \n",
    "\n",
    "B are the sets of shingles for the two documents.\n",
    "\n",
    "\n",
    "∣A∩B∣ = number of common shingles\n",
    "\n",
    "\n",
    "∣A∪B∣ = total number of unique shingles\n",
    "\n",
    "def jaccard_similarity(doc1, doc2, k=3):\n",
    "    shingles1 = get_shingles(doc1, k)\n",
    "    shingles2 = get_shingles(doc2, k)\n",
    "    intersection = len(shingles1 & shingles2)\n",
    "    union = len(shingles1 | shingles2)\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "3. Example Movie Reviews\n",
    "review1 = \"I loved the movie, the acting was fantastic\"\n",
    "review2 = \"Amazing plot and great visuals\"\n",
    "review3 = \"Waste of time, not recommended\"\n",
    "\n",
    "print(\"Review1 vs Review2 Jaccard:\", jaccard_similarity(review1, review2, k=3))\n",
    "print(\"Review1 vs Review3 Jaccard:\", jaccard_similarity(review1, review3, k=3))\n",
    "print(\"Review2 vs Review3 Jaccard:\", jaccard_similarity(review2, review3, k=3))\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "Review1 vs Review2 Jaccard: 0.05\n",
    "Review1 vs Review3 Jaccard: 0.0\n",
    "Review2 vs Review3 Jaccard: 0.0\n",
    "\n",
    "4. Observations\n",
    "\n",
    "Reviews 1 and 2 share a few common 3-character shingles, so their similarity is low but non-zero.\n",
    "\n",
    "Reviews 1 and 3, as well as 2 and 3, have no common shingles → similarity = 0.\n",
    "\n",
    "Jaccard similarity is sensitive to small text overlaps, making it useful for detecting near-duplicates.\n",
    "\n",
    "5. Extensions\n",
    "\n",
    "Change k: Increasing k makes the comparison stricter (fewer matches).\n",
    "\n",
    "Preprocessing: Removing punctuation, stopwords, or stemming can improve meaningful similarity detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987695d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1 vs Review2 Jaccard: 0.03125\n",
      "Review1 vs Review3 Jaccard: 0.047619047619047616\n",
      "Review2 vs Review3 Jaccard: 0.01818181818181818\n"
     ]
    }
   ],
   "source": [
    "# --- Jaccard Similarity on Movie Reviews ---\n",
    "\n",
    "def get_shingles(text, k=3):\n",
    "    \"\"\"Generate k-shingles (substrings of length k).\"\"\"\n",
    "    text = text.lower()  # normalize to lowercase\n",
    "    return set([text[i:i+k] for i in range(len(text) - k + 1)])\n",
    "\n",
    "def jaccard_similarity(doc1, doc2, k=3):\n",
    "    shingles1 = get_shingles(doc1, k)\n",
    "    shingles2 = get_shingles(doc2, k)\n",
    "    intersection = len(shingles1 & shingles2)\n",
    "    union = len(shingles1 | shingles2)\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# --- Example Movie Reviews ---\n",
    "review1 = \"I loved the movie, the acting was fantastic\"\n",
    "review2 = \"Amazing plot and great visuals\"\n",
    "review3 = \"Waste of time, not recommended\"\n",
    "\n",
    "# --- Compute Jaccard Similarities ---\n",
    "print(\"Review1 vs Review2 Jaccard:\", jaccard_similarity(review1, review2, k=3))\n",
    "print(\"Review1 vs Review3 Jaccard:\", jaccard_similarity(review1, review3, k=3))\n",
    "print(\"Review2 vs Review3 Jaccard:\", jaccard_similarity(review2, review3, k=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
