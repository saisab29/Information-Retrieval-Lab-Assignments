{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62117abf",
   "metadata": {},
   "source": [
    "# Evaluation of IR:\n",
    "\n",
    "Calculating ( precision, recall ,fmeasure) on results of IR models\n",
    "\n",
    "This lab demonstrates how the **Vector Space Model (VSM)** can be applied to rank documents based on **cosine similarity** between **TF-IDF vectors** of documents and a query.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We use a small set of **movie review snippets** as documents:\n",
    "\n",
    "| DocID | Content |\n",
    "|-------|---------|\n",
    "| D1    | I loved this movie the plot was exciting and the characters were amazing |\n",
    "| D2    | Terrible movie waste of time and I would not recommend it |\n",
    "| D3    | An average film some good moments but overall it was predictable |\n",
    "| D4    | Fantastic performance by the lead actor brilliant cinematography |\n",
    "| D5    | Bad script poor direction not worth watching at all |\n",
    "\n",
    "---\n",
    "\n",
    "## Query\n",
    "\n",
    "We use a sample query to find relevant documents:\n",
    "\n",
    "\n",
    "The **relevant documents** for evaluation are `{D1, D4}`.\n",
    "\n",
    "---\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "1. **Tokenization**: Split text into lowercase word tokens.  \n",
    "2. **Vocabulary creation**: Build a list of unique terms across all documents.  \n",
    "3. **TF-IDF Calculation**:\n",
    "   - **Term Frequency (TF)**: Number of times a term appears in a document.\n",
    "   - **Inverse Document Frequency (IDF)**: Measures how rare a term is across all documents.\n",
    "   - **TF-IDF**: Multiply TF by IDF to compute term weights.\n",
    "\n",
    "---\n",
    "\n",
    "## Cosine Similarity\n",
    "\n",
    "To rank documents:\n",
    "\n",
    "\\[\n",
    "\\text{cosine\\_sim}(D, Q) = \\frac{D \\cdot Q}{\\|D\\| \\|Q\\|}\n",
    "\\]\n",
    "\n",
    "- Measures similarity between **document vector** and **query vector**.  \n",
    "- Range: 0 (no similarity) to 1 (identical vectors).  \n",
    "\n",
    "Documents are ranked in descending order of cosine similarity with the query.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "We use **Precision, Recall, and F1-score** to evaluate retrieval effectiveness:\n",
    "\n",
    "- **Precision (P)**: Fraction of retrieved documents that are relevant.  \n",
    "- **Recall (R)**: Fraction of relevant documents that are retrieved.  \n",
    "- **F1-score (F1)**: Harmonic mean of precision and recall.\n",
    "\n",
    "\\[\n",
    "P = \\frac{TP}{TP + FP}, \\quad\n",
    "R = \\frac{TP}{TP + FN}, \\quad\n",
    "F1 = \\frac{2PR}{P + R}\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- TP = True Positives  \n",
    "- FP = False Positives  \n",
    "- FN = False Negatives  \n",
    "\n",
    "---\n",
    "\n",
    "## Lab Workflow\n",
    "\n",
    "1. Tokenize documents and query.  \n",
    "2. Compute TF-IDF vectors for all documents and the query.  \n",
    "3. Calculate cosine similarity between each document and the query.  \n",
    "4. Rank documents based on similarity scores.  \n",
    "5. Evaluate retrieval using Precision, Recall, and F1 at different top-k ranks.\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- This demo uses a small dataset of movie reviews for simplicity.  \n",
    "- The workflow can scale to larger datasets and more complex queries.  \n",
    "- VSM allows **ranking documents**, unlike Boolean retrieval which is strictly binary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbadbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking (DocID, CosineSimilarity):\n",
      "D1 0.5469\n",
      "D2 0.112\n",
      "D3 0.0\n",
      "D4 0.0\n",
      "D5 0.0\n",
      "@1 -> P=1.0000 R=0.5000 F1=0.6667\n",
      "@2 -> P=0.5000 R=0.5000 F1=0.5000\n",
      "@3 -> P=0.3333 R=0.5000 F1=0.4000\n",
      "@4 -> P=0.5000 R=1.0000 F1=0.6667\n",
      "@5 -> P=0.4000 R=1.0000 F1=0.5714\n"
     ]
    }
   ],
   "source": [
    "# vsm_lab_demo_movies.py\n",
    "from math import log, sqrt\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Sample movie review documents\n",
    "docs = [\n",
    "    \"I loved this movie the plot was exciting and the characters were amazing\",\n",
    "    \"Terrible movie waste of time and I would not recommend it\",\n",
    "    \"An average film some good moments but overall it was predictable\",\n",
    "    \"Fantastic performance by the lead actor brilliant cinematography\",\n",
    "    \"Bad script poor direction not worth watching at all\",\n",
    "]\n",
    "\n",
    "doc_ids = [f\"D{i + 1}\" for i in range(len(docs))]\n",
    "\n",
    "# Example query\n",
    "query = \"movie plot exciting characters\"\n",
    "\n",
    "# Set of relevant documents for evaluation\n",
    "relevant_set = {\"D1\", \"D4\"}\n",
    "\n",
    "token_pattern = re.compile(r\"[a-zA-Z]+\")\n",
    "\n",
    "def tokenize(text):\n",
    "    return [t.lower() for t in token_pattern.findall(text)]\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [tokenize(d) for d in docs]\n",
    "N = len(docs)\n",
    "\n",
    "# Compute document frequencies\n",
    "df = Counter()\n",
    "for terms in tokenized_docs:\n",
    "    for t in set(terms):\n",
    "        df[t] += 1\n",
    "\n",
    "# Compute IDF\n",
    "idf = {t: log((N + 1) / (df_t + 1)) + 1 for t, df_t in df.items()}\n",
    "\n",
    "# TF-IDF vector\n",
    "def tfidf_vector(terms):\n",
    "    tf = Counter(terms)\n",
    "    vec = {}\n",
    "    for t, freq in tf.items():\n",
    "        if t in idf:\n",
    "            vec[t] = freq * idf[t]\n",
    "    return vec\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_sim(v1, v2):\n",
    "    dot = sum(v1.get(t, 0) * v2.get(t, 0) for t in set(v1) | set(v2))\n",
    "    n1 = sqrt(sum(w * w for w in v1.values()))\n",
    "    n2 = sqrt(sum(w * w for w in v2.values()))\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return 0.0\n",
    "    return dot / (n1 * n2)\n",
    "\n",
    "# Compute document vectors\n",
    "doc_vectors = [tfidf_vector(tokenize(d)) for d in docs]\n",
    "query_vec = tfidf_vector(tokenize(query))\n",
    "\n",
    "# Compute cosine similarity scores\n",
    "scores = [\n",
    "    (doc_id, cosine_sim(query_vec, vec)) for doc_id, vec in zip(doc_ids, doc_vectors)\n",
    "]\n",
    "ranked = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Precision, Recall, F1 calculation\n",
    "def precision_recall_f1(retrieved_ids, relevant_ids):\n",
    "    retrieved_set = set(retrieved_ids)\n",
    "    tp = len(retrieved_set & relevant_ids)\n",
    "    fp = len(retrieved_set - relevant_ids)\n",
    "    fn = len(relevant_ids - retrieved_set)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (\n",
    "        (2 * precision * recall / (precision + recall))\n",
    "        if (precision + recall) > 0\n",
    "        else 0.0\n",
    "    )\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Ranking (DocID, CosineSimilarity):\")\n",
    "    for d, s in ranked:\n",
    "        print(d, round(s, 4))\n",
    "    for k in range(1, len(docs) + 1):\n",
    "        topk = [doc_id for doc_id, _ in ranked[:k]]\n",
    "        P, R, F1 = precision_recall_f1(topk, relevant_set)\n",
    "        print(f\"@{k} -> P={P:.4f} R={R:.4f} F1={F1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
