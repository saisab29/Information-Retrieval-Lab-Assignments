{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c951d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saisab31\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saisab31\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\saisab31\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03eb3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated documents for Query Operations Lab\n",
    "documents = [\n",
    "    \"I loved the movie, the plot was thrilling and the characters were amazing.\",\n",
    "    \"The film was boring and predictable, not worth my time.\",\n",
    "    \"An enjoyable movie with some funny moments and great acting.\",\n",
    "    \"Terrible direction, bad script, and poor editing ruined the movie.\",\n",
    "]\n",
    "\n",
    "# Example query\n",
    "query = \"thrilling movie\"\n",
    "\n",
    "# Vocabulary\n",
    "vocab = [\"movie\", \"plot\", \"thrilling\", \"characters\", \"boring\", \"predictable\",\n",
    "         \"enjoyable\", \"funny\", \"acting\", \"direction\", \"script\", \"editing\", \"ruined\"]\n",
    "\n",
    "# Corpus\n",
    "corpus = \" \".join(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687537a4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 1. Query Expansion\n",
    "\n",
    "**Query expansion** improves search by adding **semantically related terms** to the original query.  \n",
    "\n",
    "- Uses **WordNet** to retrieve **synonyms (lemmas)** for query words.\n",
    "- Helps retrieve documents containing related words rather than exact matches.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "query_expansion_wordnet(\"thrilling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35264f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Query Expansion (WordNet):\n",
      "['vibrate', 'pic', 'movie', 'exalt', 'flick', 'beatify', 'inebriate', 'electrifying', 'moving-picture show', 'tickle', 'picture', 'motion-picture show', 'exhilarate', 'throb', 'tickle pink', 'thrilling', 'shudder', 'moving picture', 'shiver', 'film', 'thrill', 'picture show', 'motion picture']\n"
     ]
    }
   ],
   "source": [
    "def query_expansion_wordnet(query):\n",
    "    words = nltk.word_tokenize(query)\n",
    "    expanded_query = set(words)\n",
    "    for word in words:\n",
    "        for syn in wn.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded_query.add(lemma.name().replace(\"_\", \" \"))\n",
    "    return list(expanded_query)\n",
    "\n",
    "\n",
    "print(\"1. Query Expansion (WordNet):\")\n",
    "print(query_expansion_wordnet(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d5ee8",
   "metadata": {},
   "source": [
    "---\n",
    "### 2A. Spelling Correction: Edit Distance (Levenshtein Distance)\n",
    "\n",
    "This section demonstrates **spelling correction using Edit Distance**. The code consists of two functions:\n",
    "\n",
    "#### 1. `edit_distance(w1, w2)`\n",
    "\n",
    "- Computes the **minimum number of single-character edits** (insertions, deletions, substitutions) to convert `w1` to `w2`.\n",
    "- Uses a **dynamic programming matrix** `dp` of size `(len(w1)+1) x (len(w2)+1)`.\n",
    "- Filling the matrix:\n",
    "  - `dp[i][0] = i` → deleting all characters from `w1`\n",
    "  - `dp[0][j] = j` → inserting all characters from `w2`\n",
    "  - `dp[i][j] = dp[i-1][j-1]` if characters match\n",
    "  - `dp[i][j] = 1 + min(deletion, insertion, substitution)` if characters differ\n",
    "\n",
    "#### 2. `correct_by_edit_distance(word, vocab)`\n",
    "\n",
    "- Finds the **closest word** in the vocabulary to the misspelled word.\n",
    "- Computes `edit_distance` for each vocabulary word.\n",
    "- Returns the word with **minimum distance** as the correction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68bb1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2A. Edit Distance Correction:\n",
      "thrilling\n"
     ]
    }
   ],
   "source": [
    "# A. Edit Distance\n",
    "def edit_distance(w1, w2):\n",
    "    dp = [[0] * (len(w2) + 1) for _ in range(len(w1) + 1)]\n",
    "    for i in range(len(w1) + 1):\n",
    "        for j in range(len(w2) + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif w1[i - 1] == w2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "    return dp[-1][-1]\n",
    "\n",
    "\n",
    "def correct_by_edit_distance(word, vocab):\n",
    "    min_dist = float(\"inf\")\n",
    "    correction = word\n",
    "    for w in vocab:\n",
    "        dist = edit_distance(word, w)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            correction = w\n",
    "    return correction\n",
    "\n",
    "\n",
    "print(\"\\n2A. Edit Distance Correction:\")\n",
    "print(correct_by_edit_distance(\"thrillnig\", vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88bf224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2B. K-Gram Correction:\n",
      "script\n"
     ]
    }
   ],
   "source": [
    "# B. K-Gram Index\n",
    "def generate_k_grams(word, k=3):\n",
    "    word = f\"${word}$\"\n",
    "    return [word[i : i + k] for i in range(len(word) - k + 1)]\n",
    "\n",
    "\n",
    "def kgram_index(vocab, k=3):\n",
    "    index = defaultdict(set)\n",
    "    for word in vocab:\n",
    "        grams = generate_k_grams(word, k)\n",
    "        for g in grams:\n",
    "            index[g].add(word)\n",
    "    return index\n",
    "\n",
    "\n",
    "def correct_by_kgram(word, index, vocab, k=3):\n",
    "    grams = generate_k_grams(word, k)\n",
    "    candidates = Counter()\n",
    "    for g in grams:\n",
    "        for cand in index.get(g, []):\n",
    "            candidates[cand] += 1\n",
    "    if not candidates:\n",
    "        return word\n",
    "    # Get candidates with highest overlap\n",
    "    max_overlap = candidates.most_common(1)[0][1]\n",
    "    best_candidates = [w for w, c in candidates.items() if c == max_overlap]\n",
    "    # Choose the one with smallest edit distance\n",
    "    return min(best_candidates, key=lambda w: edit_distance(word, w))\n",
    "\n",
    "\n",
    "print(\"\\n2B. K-Gram Correction:\")\n",
    "k_index = kgram_index(vocab)\n",
    "print(correct_by_kgram(\"scrit\", k_index, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca9d540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2C. Context Sensitive:\n",
      "['boring', 'bor']\n"
     ]
    }
   ],
   "source": [
    "# C. Context Sensitive Correction (Bigram Based)\n",
    "def train_bigram_model(corpus):\n",
    "    tokens = nltk.word_tokenize(corpus.lower())\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    model = Counter(bigrams)\n",
    "    return model\n",
    "\n",
    "\n",
    "def correct_contextually(word_list, model, vocab):\n",
    "    corrected = [word_list[0]]\n",
    "    for i in range(1, len(word_list)):\n",
    "        prev_word = corrected[-1]\n",
    "        word = word_list[i]\n",
    "        candidates = [word, correct_by_edit_distance(word, vocab)]\n",
    "        best_word = max(candidates, key=lambda w: model.get((prev_word, w), 0))\n",
    "        corrected.append(best_word)\n",
    "    return corrected\n",
    "\n",
    "\n",
    "print(\"\\n2C. Context Sensitive:\")\n",
    "bigram_model = train_bigram_model(corpus)\n",
    "print(correct_contextually([\"boring\", \"bor\"], bigram_model, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064ac28",
   "metadata": {},
   "source": [
    "# 3. Query Language Interpreter\n",
    "A. Single-Word Queries\n",
    "\n",
    "Matches documents containing the exact word.\n",
    "Example:\n",
    "\n",
    "movie → [\n",
    "    \"I loved the movie, the plot was thrilling and the characters were amazing.\",\n",
    "    \"An enjoyable movie with some funny moments and great acting.\",\n",
    "    \"Terrible direction, bad script, and poor editing ruined the movie.\"\n",
    "]\n",
    "\n",
    "B. Boolean Queries\n",
    "\n",
    "Combines terms using logical operators: AND, OR, NOT.\n",
    "Example:\n",
    "\n",
    "thrilling AND movie → [\n",
    "    \"I loved the movie, the plot was thrilling and the characters were amazing.\"\n",
    "]\n",
    "\n",
    "C. Natural Language Queries\n",
    "\n",
    "Interprets queries in plain English by tokenizing into keywords.\n",
    "Example:\n",
    "\n",
    "\"Was the movie exciting?\" → [\n",
    "    \"I loved the movie, the plot was thrilling and the characters were amazing.\",\n",
    "    \"An enjoyable movie with some funny moments and great acting.\"\n",
    "]\n",
    "\n",
    "D. Structural Queries\n",
    "\n",
    "Targets specific fields (title, body, etc.).\n",
    "\n",
    "Example: title:script returns documents containing \"script\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87b07db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3A. Single-word Query:\n",
      "['I loved the movie, the plot was thrilling and the characters were amazing.']\n"
     ]
    }
   ],
   "source": [
    "def single_word_query(word, documents):\n",
    "    return [doc for doc in documents if word in doc.lower()]\n",
    "\n",
    "\n",
    "print(\"\\n3A. Single-word Query:\")\n",
    "print(single_word_query(\"plot\", documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "775447f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3B. Boolean Query:\n",
      "['I loved the movie, the plot was thrilling and the characters were amazing.']\n"
     ]
    }
   ],
   "source": [
    "def boolean_query(q, documents):\n",
    "    terms = q.lower().split()\n",
    "    result = set(documents)\n",
    "    if \"and\" in terms:\n",
    "        terms = [t for t in terms if t != \"and\"]\n",
    "        result = [doc for doc in documents if all(t in doc.lower() for t in terms)]\n",
    "    elif \"or\" in terms:\n",
    "        terms = [t for t in terms if t != \"or\"]\n",
    "        result = [doc for doc in documents if any(t in doc.lower() for t in terms)]\n",
    "    elif \"not\" in terms:\n",
    "        idx = terms.index(\"not\")\n",
    "        term = terms[idx + 1]\n",
    "        result = [doc for doc in documents if term not in doc.lower()]\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"\\n3B. Boolean Query:\")\n",
    "print(boolean_query(\"movie AND plot\", documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f010ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3C. Natural Language Query:\n",
      "['I loved the movie, the plot was thrilling and the characters were amazing.', 'The film was boring and predictable, not worth my time.', 'Terrible direction, bad script, and poor editing ruined the movie.']\n"
     ]
    }
   ],
   "source": [
    "def natural_language_query(nl_query, documents):\n",
    "    tokens = nltk.word_tokenize(nl_query.lower())\n",
    "    return [doc for doc in documents if any(t in doc.lower() for t in tokens)]\n",
    "\n",
    "\n",
    "print(\"\\n3C. Natural Language Query:\")\n",
    "print(natural_language_query(\"Was the plot good?\", documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3117705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3D. Structural Query:\n",
      "['I loved the movie, the plot was thrilling and the characters were amazing.', 'An enjoyable movie with some funny moments and great acting.', 'Terrible direction, bad script, and poor editing ruined the movie.']\n"
     ]
    }
   ],
   "source": [
    "def structural_query(structure_query, documents):\n",
    "    # Dummy: match title:xxx or body:xxx\n",
    "    m = re.match(r\"(title|body):(\\w+)\", structure_query.lower())\n",
    "    if m:\n",
    "        field, word = m.groups()\n",
    "        return [doc for doc in documents if word in doc.lower()]\n",
    "    return []\n",
    "\n",
    "\n",
    "print(\"\\n3D. Structural Query:\")\n",
    "print(structural_query(\"title:movie\", documents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
